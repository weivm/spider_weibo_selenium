# **基于selenium模式spider**

本项目采用firefox驱动,爬取weibo热搜榜目前获取(链接,热搜名,数量可以根据自己情况)目前只是写入CSV文件,可以根据自己需求
**仅作为学习交流记录**


## WEB爬虫模式基本流程

(发起请求->读取BODY->中间件动态代理OR其他操作->管道数据清洗落地)




## 如何启动
1. *pip install -r requirements.txt*


2. *scrapy crawl  wb*




## 总结目前经历常见场景

1. **WEB地址是由接口渲染且URL会变化直接最简单模式拿到地址直接请求**
2. **WEB数据数据有JS动态加载使用selenium(页面基本都能解决只是每次写这个比较繁琐)**
3. **有些网页请求和返回加密处理,使用检查查看加解密过程,需要JS知识
   使用execjs,将加解密写成一份JS文件在编译起来,然后在中间件写一个初始化,数据来的时候或者请求进行数据或者参数加解密**
4. **额外爬虫需要登录
   登录时候最多就是输入一些信息然后什么数字相加或者图片数字是什么,没成本的就找些OCR免费识别把他下载在做成手动输入请求时候去请求登录**




## tips

**本案例实现常见场景2学习,基本覆盖大多数情况,剩下有时间在实现,使用时ROBOTSTXT_OBEY遵循网页规定**

